"""Service – Speech-to-text helper (Whisper)."""

import asyncio
import os
from pathlib import Path
import uuid

from litellm import transcription  # type: ignore
from deepgram import DeepgramClient, PrerecordedOptions  # type: ignore
from app.infra.config import settings

import json

# Deepgram client initialised lazily
deepgram: DeepgramClient | None = None


def _ensure_deepgram_client() -> DeepgramClient:
    """Return a singleton Deepgram client (initialise if needed)."""

    global deepgram
    if deepgram is None:
        deepgram = DeepgramClient(settings.deepgram_api_key)
    return deepgram

async def transcribe_file(file_path: str, model: str = "whisper-1") -> str:
    """Transcribe an audio file already persisted on disk.

    If `settings.use_deepgram` is **truthy** and the Deepgram API key is set, the
    audio is sent to Deepgram; otherwise it falls back to OpenAI Whisper via
    `litellm.transcription`.
    """

    def _sync_run_deepgram() -> str:
        dg = _ensure_deepgram_client()
        with open(file_path, "rb") as buffer_data:
            payload = {"buffer": buffer_data}
            options = PrerecordedOptions(
                smart_format=True,
                model="nova-2",
                language="en-US",
            )
            response = dg.listen.prerecorded.v("1").transcribe_file(payload, options)
            dg_resp = json.loads(response.to_json(indent=4))
            return (
                dg_resp.get("results", {})
                .get("channels", [{}])[0]
                .get("alternatives", [{}])[0]
                .get("transcript", "")
            )

    def _sync_run_whisper() -> str:
        with open(file_path, "rb") as audio_file:
            resp = transcription(model=model, file=audio_file)
            return resp.get("text", "").strip()

    loop = asyncio.get_event_loop()
    if settings.use_deepgram and settings.deepgram_api_key:
        return await loop.run_in_executor(None, _sync_run_deepgram)
    else:
        return await loop.run_in_executor(None, _sync_run_whisper) 


# ---------------------------------------------------------------------------
# Convenience wrapper – transcribe in-memory bytes by writing to a temp file.
# ---------------------------------------------------------------------------


async def transcribe_bytes(
    data: bytes,
    *,
    session_id: str | None = None,
    turn: int | None = None,
    model: str = "whisper-1",
) -> str:
    """Persist *data* to the same `data/<session_id>/<turn>.webm` path used
    by the REST endpoint, then delegate to `transcribe_file`.

    Parameters
    ----------
    data        : raw audio bytes (WebM/Opus from MediaRecorder)
    session_id  : conversation identifier; a random UUID if omitted
    turn        : integer turn index; autogenerated if omitted
    model       : Whisper/Deepgram model name
    """

    # ------------ resolve storage dir (mirrors app.main logic) -------------
    if os.environ.get("VERCEL"):
        data_dir = Path("/tmp") / "data"
    else:
        data_dir = Path(__file__).parents[2] / "data"

    sid = (session_id or uuid.uuid4().hex).replace("..", "")  # simple sanitise
    turn = turn if turn is not None else 0

    session_dir = data_dir / sid
    session_dir.mkdir(parents=True, exist_ok=True)
    audio_path = session_dir / f"{turn}.webm"

    # ------------ write bytes to disk --------------------------------------
    with open(audio_path, "wb") as fp:
        fp.write(data)

    # ------------ transcribe ----------------------------------------------
    try:
        return await transcribe_file(str(audio_path), model=model)
    finally:
        # Clean up to save disk space
        try:
            pass
            audio_path.unlink()
            session_dir.rmdir()  # only removed if empty
        except OSError:
            # Either file already gone or dir not empty – ignore.
            pass 